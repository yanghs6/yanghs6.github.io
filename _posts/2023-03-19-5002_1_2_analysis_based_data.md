---
date: 2023-03-19 13:10:00 +/-0900
title: "[Data] [빅데이터를 지탱하는 기술] 정리하기 - 1-2 빅데이터 시대의 데이터 분석 기반"
categories: [Data, concept]
tags: [데이터(data), 개념(concept), 역사(history), 빅데이터(bigdata), 데이터파이프라인(data_pipeline), 분산스토리지(distributed_storage), 워크플로관리(workflow_management), 데이터웨어하우스(data_warehouse), 데이터레이크(data_lake), 데이터마트(data_mart), 대시보드(dashboard)]

---
## 개요

- [빅데이터를 지탱하는 기술] 정리하기 시리즈
  1. [[Data] "빅데이터를 지탱하는 기술" 정리하기 - 1-1 [배경] 빅데이터의 정착]({% post_url 2023-03-12-5001_1_1_bigdata_history %})
  2. [[Data] "빅데이터를 지탱하는 기술" 정리하기 - 1-2 빅데이터 시대의 데이터 분석 기반]({% post_url 2023-03-19-5002_1_2_analysis_based_data %})
  3. [[Data] "빅데이터를 지탱하는 기술" 정리하기 - 1-3 [속성 학습] 스크립트 언어에 대한 특별 분석과 데이터 프레임]({% post_url 2023-03-26-5003_1_3_script_language_and_dataframe %})
  4. [[Data] "빅데이터를 지탱하는 기술" 정리하기 - 1-4 BI 도구와 모니터링]({% post_url 2023-04-09-5004_1_4_BI_tool_and_monitoring %})

안녕하세요.

이번 글에서는 "빅데이터를 지탱하는 기술" 이라는 책의 1장 2절, "빅데이터 시대의 데이터 분석 기반"을 정리했습니다.

---
## [재입문] 빅데이터의 기술 - 분산 시스템을 활용해서 데이터를 가공해 나가는 구조

### 데이터 파이프라인 - 데이터 수집에서 워크플로 관리까지

**<u>데이터 파이프라인(Data Pipeline)</u>**이란 차례대로 전달해나가는 데이터로 구성된 시스템입니다.

빅데이터의 데이터 파이프라인은 어디에서 데이터를 수집하여 무엇을 실현하고 싶은지에 따라 변화합니다.

처음에는 간단한 구성으로 시작하지만 요구사항이 늘어나면서 복잡해지는 시스템을 어떻게 조합할지 문제가 됩니다.

### 데이터 수집 - 벌크 형과 스트리밍 형의 데이터 전송

데이터는 DB의 거래처 데이터, 파일 서버의 로그 파일, 모바일 애플리케이션의 이벤트 데이터, 임베디드 장비의 센서 등 각각 서로 다른 기술에서 생성되고 전송됩니다.

이러한 **<u>데이터 전송(Data Transfer)</u>**은 크게 벌크형(Bulk)와 스트리밍형(Streaming)으로 구분됩니다. ([그림 1] ❶, ❷)

![빅데이터를 위한 파이프라인](/assets/img/data/5002/5002_01_pipeline_for_bigdate.png)
_[그림 1] 빅데이터를 위한 파이프라인_

두 가지 방식의 특징은 다음 표와 같습니다.

| 구분     | 벌크형                                            | 스트리밍형                                                  |
| :------: | ------------------------------------------------- | ----------------------------------------------------------- |
| 설명     | 이미 존재하는 데이터를 정리해 추출                | 차례로 생성되는 데이터를 끊임없이 계속해서 전송             |
| 사용시기 | DB와 파일 서버 등에서 정기적으로 데이터 수집할 때 | 모바일 애플리케이션과 임베디드 장비 등에서 데이터 수집할 때 |

### 스트림 처리와 배치 처리

기존의 데이터 웨어하우스 데이터는 벌크형 방법 이용했습니다.

하지만 스트리밍형 방법이 주류가 되면서 실시간 처리의 수요 증가했고, **<u>스트림 처리(Stream Processing)</u>**가 등장하게 됩니다.

예를 들어, 과거 30분간 취합한 데이터를 집계하여 그래프 생성 필요하다고 가정하겠습니다.

이런 경우 **<u>시계열 데이터 베이스(Time-Series Database)</u>**와 같이 실시간 처리를 지향하는 DB를 사용합니다.([그림 1] ❸)

한편, 스트림 처리는 장기적인 데이터 분석에 적합하지 않습니다.

지난 1년간의 데이터를 분석한다면 데이터 양이 수천 ~ 수만 배로 늘어납니다.

따라서 대량의 데이터를 저장하고 처리하는 데 적합한 분산 시스템 사용합니다.([그림 1] ❹, ❺)

위와 같은 상황에 필요한 것은 어느 정도 정리된 데이터를 효율적을 가공하는 **<u>배치 처리(Batch Processing)</u>** 구조입니다.

### 분산 스토리지 - 객체 스토리지, NoSQL 데이터베이스

수집 데이터는 분산 스토리지(Distributed Storage)에 저장됩니다.([그림 1] ❷, ❹)

데이터 저장에는 몇 가지 방법이 존재합니다.

첫 번째는 **<u>객체 스토리지(Object Storage)</u>**입니다.

한 덩어리로 모인 데이터에 이름을 부여하여 파일로 저장합니다. 

대표적으로 클라우드 서비스인 Amazon S3, Google GCS 등이 있습니다.

두 번째는 **<u>NoSQL 데이터베이스</u>**입니다.

애플리케이션에서 많은 데이터를 읽고 쓴다면 NoSQL 데이터베이스가 보다 우수한 성능을 보여줍니다.

단, 데이터 용량을 늘릴 수 있는 확장성 높은 제품이 필요합니다.

### 분산 데이터 처리 - 쿼리 엔진, ETL 프로세스

분산 스토리지에 저장된 데이터 처리는 **<u>분산 데이터 처리(Distributed Data Processing)</u>** 프레임워크가 담당합니다.([그림 1] ❻, ❼)

MapReduce가 사용된 부분으로 데이터 양과 처리의 내용에 따라 많은 컴퓨터 자원이 필요합니다.

이러한 분산 데이터 처리는 분석에 용이하도록 데이터를 가공하여 결과를 외부 DB에 저장하는 역할을 담당합니다.

빅데이터를 SQL로 집계하는 방법에는 다음 2가지 방법이 있습니다.

먼저 분산 스토리지 상의 데이터를 SQL로 집계하는 **<u>쿼리 엔진(Query Engine)</u>**입니다.

다른 방법에는 외부 DW 제품을 이용하는 방법이 있습니다.

이를 위해 분산 스토리지에서 추출한 데이터를 DW에 적합하게 변환합니다.

위의 절차가 **<u>ETL(Extract-Transform-Load) 프로세스</u>**로 데이터를 추출(Extract)하고, 이를 변환(Transform)한 뒤, 결과물을 적재(Load)합니다.

### 워크플로 관리

**<u>워크플로 관리(Workflow Management)</u>**란 전체 데이터 파이프라인의 동작을 관리하는 기술입니다.

데이터 파이프라인이 복잡해지면서, 한 곳에서 제어할 필요성이 커졌습니다.

따라서 오류 발생 시의 처리와 다시 처리하기 위한 기능이 필수적입니다.

![ETL 프로세스](/assets/img/data/5002/5002_02_ETL_process.png)
_[그림 2] ETL 프로세스_

---
## 데이터 웨어하우스와 데이터 마트 - 데이터 파이프라인 기본형

![데이터 웨어하우스를 중심으로 하는 데이터 파이프라인](/assets/img/data/5002/5002_03_pipeline_based_data_warehouse.png)
_[그림 3] 데이터 웨어하우스를 중심으로 하는 데이터 파이프라인_

데이터 웨어하우스(Data Warehouse)는 웹서버나 업무 시스템에 이용되는 RDB와 다르게 대량의 데이터를 장기 보존하는 것에 최적화되어 있습니다.

예를 들어 업무 시스템에서 꺼낸 데이터를 하루가 끝날 때 정리하여 쓰고, 이것을 야간 시간대에 집계해서 보고서를 작성합니다.

업무 시스템을 위한 RDB나 로그 등을 저장하는 파일 서버를 **<u>데이터 소스(Data Source)</u>**라고 합니다.

여기에 보존된 **<u>로우 데이터(Raw Data, 원시 데이터)</u>**를 필요에 따라 가공한 후 데이터 웨어하우스에 저장하기까지의 흐름이 **<u>ETL 프로세스(ETL Process)</u>**입니다.

데이터 웨어하우스 구축에는 ‘ETL 도구’라는 전용 소프트웨어를 이용합니다.

데이터 분석과 같은 목적의 경우 데이터 웨어하우스에서 필요한 데이터만 추출하여 **<u>데이터 마트(Data Mart)</u>**를 구축합니다.

데이터 마트는 BI 도구와 조합해 데이터 시각화에도 사용됩니다.

데이터 웨어하우스와 데이터 마트는 모두 SQL로 데이터를 집계합니다.

따라서 테이블의 설계와 이에 맞는 ETL 프로세스의 정립이 중요합니다.

---
## 데이터 레이크 - 데이터를 그대로 축적

### 데이터 레이크(Data Lake)

빅데이터 시대가 되면서 ETL 프로세스가 복잡해집니다.

우선 데이터가 있고, 나중에 테이블을 설계하는 것이 빅데이터입니다.

따라서 모든 데이터를 원래의 형태로 축적하고 나중에 그것을 필요에 따라 가공하는 구조인 **<u>데이터 레이크(Data Lake)</u>**가 등장합니다.

보통 임의의 데이터를 저장할 수 있는 분산 스토리지가 데이터 레이크를 이용됩니다.

데이터 형식은 자유지만, 대부분 CSV, JSON 등 범용적인 텍스트 형식을 채택합니다.

![데이터 레이크의 이미지](/assets/img/data/5002/5002_04_data_lake.png)
_[그림 4] 데이터 레이크의 이미지_

데이터 웨어하우스를 데이터 레이크로 치환하면, [그림 5]와 같은 데이터 파이프라인을 구축할 수 있습니다.

![데이터 레이크를 중심으로 하는 데이터 파이프라인](/assets/img/data/5002/5002_05_pipeline_based_data_lake.png)
_[그림 5] 데이터 레이크를 중심으로 하는 데이터 파이프라인_

### 데이터 레이크와 데이터 마트 - 필요한 데이터는 데이터 마트에 정리

데이터 레이크는 단순 스토리지로 데이터 가공 불가능합니다.

그래서 MapReduce 등 분산 데이터 처리 기술을 사용합니다.

데이터 분석 필요한 데이터를 가공, 집계하고, 이것을 데이터 마트로 추출한다면 데이터 웨어하우스처럼 분석이 가능합니다.

---
## 데이터 분석 기반을 단계적으로 발전시키기 - 팀과 역할 분담, 스몰 스타트와 확장

데이터 분석에 필요한 기술은 다방면에 걸쳐 있어 주로 팀을 이루어 작업합니다.

**<u>데이터 엔지니어(Data Engineer)</u>**는 시스템 구축 및 운용, 자동화를 담당합니다.

한편 **<u>데이터 분석가(Data Analyst)</u>**는 데이터에서 가치 있는 정보를 추출합니다.

![데이터 엔지니어와 데이터 분석가의 역할 분담](/assets/img/data/5002/5002_06_difference_between_data_engineer_data_analyst.png)
_[그림 6] 데이터 엔지니어와 데이터 분석가의 역할 분담_

하지만 현실적으로 항상 팀을 구성해 역할 분담하는 것은 불가능합니다.

따라서 데이터 분석을 시작하려는 경우, 작은 시스템에서 시작해 단계적으로 확장해나가는 것이 좋습니다.

### 애드 혹 분석 및 대시보드 도구

**<u>애드 혹 분석(Ad Hoc Analysis)</u>**이란 일회성 데이터 분석을 의미합니다.

SQL 쿼리 작성 후 실행하거나 스프레드시트에서 그래프 생성하는 등의 수작업도 모두 애드 혹 분석에 포함됩니다.

애드 혹 분석에서는 데이터 마트 없이 데이터 레이크와 데이터 웨어하우스에 직접 연결하는 경우([그림 7] ❶)가 많습니다.

수작업으로 데이터 분석 뿐만 아니라 정기적으로 그래프와 보고서를 만들고 싶을 때는 **<u>대시보드 도구(Dashboard Tool)</u>**를 도입합니다.

일부 대시보드 도구는 데이터 마트 없어도 동작하도록 설계되어 있으므로 설정한 스케줄에 따라 쿼리 실행 및 그래프 생성합니다.

![데이터 분석 기반의 발전](/assets/img/data/5002/5002_07_data_analysis_based_development.png)
_[그림 7] 데이터 분석 기반의 발전_

### 데이터 파이프라인의 큰 흐름은 변하지 않는다 - 도구 선택의 두 가지 힌트

빅데이터를 다루는 도구는 정말 다양해서 선택을 주저하게 됩니다.

하지만 다음 두 가지만 파악한다면 크게 문제 될 일은 없습니다.

1. 제한 없이 저장할 수 있는 데이터 용량
2. 데이터를 효율적으로 추출할 수단

새로운 도구와 서비스가 계속 개발되고 있지만, 데이터 파이프라인의 전체적인 기본 흐름은 동일합니다.

![데이터 파이프라인의 큰 흐름은 변하지 않는다](/assets/img/data/5002/5002_08_big_flow_of_data_pipeline_remains.png)
_[그림 8] 데이터 파이프라인의 큰 흐름은 변하지 않는다_

### 데이터 마트와 워크플로 관리

복잡한 데이터 분석에서는 데이터 마트 구축 이후 분석 또는 시각화를 합니다.([그림 7] ❷)

시각화에 BI 도구를 사용한다면 집계 속도를 높이기 위해 데이터 마트가 필수적입니다.

데이터 마트 구축은 배치 처리로 자동화되는 경우가 많으므로 실행 관리 위해 워크플로 관리 도구 사용합니다.

---
## 데이터를 수집하는 목적 - ‘검색’, ‘가공’, ‘시각화’의 세 가지 예

![데이터 이용 목적의 예](/assets/img/data/5002/5002_09_example_of_data_usage_purpose.png)
_[그림 9] 데이터 이용 목적의 예_

### 데이터 검색

위의 그림에서 [그림 9] ❶에 해당합니다.

언제 무엇이 필요할 지 모르므로 시스템 로그 및 고객 행동 이력 등 발생하는 모든 데이터 취득합니다.

필요할 때 신속하게 검색할 수 있도록 실시간 데이터 처리나 검색 엔진 사용해 키워드를 찾는 기능이 필요합니다.

### 데이터 가공

위의 그림에서 [그림 9] ❷에 해당합니다.

업무 시스템 일부로 데이터 처리 결과를 이용하고 싶은 경우 필요한 데이터를 계획적으로 모아 데이터 파이프라인을 설계합니다.

워크플로 관리를 도입해 꼼꼼하게 테스트를 반복 실행해서 시스템 구축합니다.

이 경우 SQL이 아닌 프로그래밍 언어도 사용할 떄도 있는데 이는 데이터 분석보다는 시스템 개발 영역에 해당합니다.

### 데이터 시각화

위의 그림에서 [그림 9] ❸에 해당합니다.

시각화의 고속화를 위해서는 역시 데이터 마트가 필요합니다.

또한 집계 결과를 대시보드에 정리해서 지속적인 변화를 감시하고 싶을 때도 데이터 시각화는 필요합니다.

### 기간계 시스템과 정보계 시스템의 분리

컴퓨터 시스템은 종종 **<u>기간계 시스템(Mission-critical System)</u>**과 **<u>정보계 시스템(Information System)</u>**로 구분됩니다.

기간계 시스템은 비즈니스 근간에 관련된 중요 시스템으로 중지 시 업무에 중대한 영향을 미칩니다.

한편 정보계 시스템은 사내 커뮤니케이션과 의사 결정 등을 위해 이용하며 정지되어도 영향이 제한적입니다.

여기서 데이터란 기간계와 정보계 시스템을 연결하는 것입니다.

기간계 시스템은 실행 과정을 로그 파일이나 DB 등에 기록합니다.

반면 데이터 분석 시스템은 정보계 시스템에 해당하며 분석에 필요한 데이터를 복사 후 가공 및 사용합니다.

---
## 확증적 데이터 분석과 탐색적 데이터 분석

데이터 분석은 크게 **<u>확증적 데이터 분석(Confirmatory Data Analysis; CDA)</u>**와 **<u>탐색적 데이터 분석(Exploratory Data Analysis; EDA)</u>**로 나뉩니다.

CDA는 통계학적 모델링을 이용하는 반면 EDA는 데이터를 시각화 하여 사람의 힘으로 의미를 탐색합니다.

이 책에서의 데이터 분석은 EDA를 의미합니다!

---
## 마무리하며

이번 글에서는 빅데이터의 데이터 분석 기반에 대해 간략하게 알아보았습니다.

빅데이터를 분석하기 위해서는 데이터를 수집부터 가공, 전체 워크플로를 관리하는 데이터 파이프라인 시스템이 필요합니다.

데이터 수집에는 크게 벌크형과 스트리밍형으로 나뉘며 데이터 처리는 스트림 처리와 배치 처리로 나뉩니다.

이러한 데이터 파이프라인 동작의 관리를 위해 워크플로 관리 기술이 필요합니다.

데이터 파이프라인은 기본적으로 데이터 웨어하우스 혹은 데이터 레이크에서 데이터 마트에 저장하고 애드 혹 분석과 대시보드에서 이 데이터를 사용합니다.

이 글이 조금이나마 도움이 되셨으면 합니다.

감사합니다. 😀

---
## 참고 문헌

- 니시다 케이스케, *빅데이터를 지탱하는 기술*, 제이펍, 2018
